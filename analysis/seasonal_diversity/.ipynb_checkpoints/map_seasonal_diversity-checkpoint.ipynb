{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd4264e-f262-45ce-9b27-40b73947c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import cartopy.crs as crs\n",
    "import panel as pn\n",
    "import hvplot.xarray\n",
    "from rasterio.plot import reshape_as_raster\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import os\n",
    "import datetime\n",
    "import daylight\n",
    "import pytz\n",
    "from shapely.geometry import Point\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import normalize\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from eofs.xarray import Eof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ca25a5-9e3a-49ac-a21c-aefab3441158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting params\n",
    "subplots_adj_left=0.05\n",
    "subplots_adj_bottom=0.1\n",
    "subplots_adj_right=0.95\n",
    "subplots_adj_top=0.9\n",
    "subplots_adj_wspace=0.2\n",
    "subplots_adj_hspace=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58eeef0-7b77-42de-a77d-7b82ca9f8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE on memory requirements\n",
    "    #        I estimate that the global 365 x 2400 x 6900 raster will take up\n",
    "    #       about 46.1 GB memory;\n",
    "    #       (NOTE: I could also cast of dtype float32 and cut down to ~23 GB,\n",
    "    #              for 'safety' sake)\n",
    "    #       if I ran this on savio bigmem that would only be ~1/9th total RAM,\n",
    "    #       so it should be doable to create a giant global 365 x 2400 x 6900\n",
    "    #       numpy array and then fill it with all fitted time series and write\n",
    "    #       to disk, though that's only ~1/2 RAM on savio3, so first just try\n",
    "    #       there!\n",
    "    #       then I could separately read in as a dask array and run EOF\n",
    "    #       analysis on that, I believe.\n",
    "    #       though I wonder if I could just run the EOF analysis within that\n",
    "    #       same job. Not sure how much memory requirement expands as factor\n",
    "    #       of size of base spatiotemporal dataset, and not easily finding that\n",
    "    #       informiation on line...\n",
    "\n",
    "\n",
    "# TODO:\n",
    "\n",
    "    # could use clustering afterward, with scree plot, to determine k\n",
    "    # distinct 'classes' of global phenological seasonality 'types'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b952b9d-d917-401c-862f-38995e521d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# BEHAVIORAL PARAMS\n",
    "###################\n",
    "\n",
    "# min and max x and y values, to optionally subset analysis to a region\n",
    "region_name = 'norcal'\n",
    "min_x = -124\n",
    "max_x = -120\n",
    "min_y = 37\n",
    "max_y = 41\n",
    "\n",
    "\n",
    "# analyses to run\n",
    "run_eof = True\n",
    "run_mds = False\n",
    "\n",
    "# use hvplot, etc for interactive plotting?\n",
    "interactive = False\n",
    "\n",
    "# save figures and datasets?\n",
    "save_res = False\n",
    "\n",
    "# data dir on laptop\n",
    "if os.getcwd().split('/')[1] == 'home':\n",
    "    data_dir = '/home/deth/Desktop/CAL/research/projects/seasonality/results/maps'\n",
    "# data dir on savio\n",
    "else:\n",
    "    data_dir = '/global/scratch/users/drewhart/seasonality/'\n",
    "\n",
    "# set the seed\n",
    "set_seed = True\n",
    "if set_seed:\n",
    "    seed = 1\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# rotate fitted ts 180deg for S-hemisphere sites?\n",
    "# NOTE: I don't think this makes any difference actually,\n",
    "#       based on initial exploration (seemed to change color but not\n",
    "#       point-point relationships), but just to be able to eplore this more...\n",
    "rotate_s_hemis = False\n",
    "\n",
    "# normalize each ts to itself?\n",
    "# NOTE: I think it makes sense to do this, since I'm only interested in timing,\n",
    "#       and otherwise (especially based on Alex Turner's results in CA) I\n",
    "#       expect the first EOF will largely reflect global (i.e.,\n",
    "#       cross-study-area) variation in magnitude of fitted values;\n",
    "#       nonetheless, setting a flag for this so that I can check that\n",
    "#       expectation and check sensitivity to this decision\n",
    "normalize_ts = False\n",
    "\n",
    "# latitude weights to use?\n",
    "lat_weights = 'cos'\n",
    "#lat_weights = 'sqrt_cos'\n",
    "#lat_weights = None\n",
    "\n",
    "# center the data being input to EOF?\n",
    "# TODO: decide about this!\n",
    "center_eof = True\n",
    "\n",
    "# number of top EOFs to use?\n",
    "neofs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf161a1c-0e15-4326-b571-9b6a3fec107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# FUNCTIONS\n",
    "###########\n",
    "\n",
    "def make_design_matrix():\n",
    "    \"\"\"\n",
    "    Makes and returns the regression's design matrix, a 365 x 5 numpy array\n",
    "    in which the columns contain, in order:\n",
    "        - 1s (for the constant);\n",
    "        - sin and cos of annual-harmonic days of the year\n",
    "          (i.e. days are expressed in radians from 0 to 2pi);\n",
    "        - sin and cos of the semiannual-harmonic days of the year\n",
    "          (i.e. days are expressed in radians from 0 to 4pi).\n",
    "    \"\"\"\n",
    "    # get 1 year of daily values, expressed in radians, 1 rotation/yr\n",
    "    annual_radian_days = np.linspace(0, 2*np.pi, 366)[:365]\n",
    "    # get 1 year of daily values, expressed in radians, 2 rotations/yr\n",
    "    semiannual_radian_days = np.linspace(0, 4*np.pi, 366)[:365] % (2 * np.pi)\n",
    "    # get the harmonic values of those\n",
    "    sin1 = np.sin(annual_radian_days)\n",
    "    cos1 = np.cos(annual_radian_days)\n",
    "    sin2 = np.sin(semiannual_radian_days)\n",
    "    cos2 = np.cos(semiannual_radian_days)\n",
    "    # add a vector of 1s for the constant term, then recast as a 365 x 5 array,\n",
    "    # to use as the covariate values in the regression\n",
    "    design_mat = np.array([np.ones(sin1.shape), sin1, cos1, sin2, cos2]).T\n",
    "    return design_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d731a4a8-1519-47a2-853b-adff3ee56f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# READ IN COEFFS, GET ARRAY OF FITTED TS\n",
    "########################################\n",
    "\n",
    "# read global NIRv coeffs\n",
    "coeffs = rxr.open_rasterio(os.path.join(data_dir, 'NIRv_global_coeffs.tif'))\n",
    "\n",
    "# subset global raster to study area (if all Nones then not subsetted!)\n",
    "# NOTE: max_y and min_y flipped because y res negative in CRS transform\n",
    "coeffs = coeffs.sel(x=slice(min_x, max_x), y=slice(max_y, min_y))\n",
    "\n",
    "# create empty time-series array for EOF analysis\n",
    "ts_arr = np.ones((365, coeffs.shape[1], coeffs.shape[2]), dtype=np.float32) * np.nan\n",
    "\n",
    "# make the harmonic regression's design matrix\n",
    "dm = make_design_matrix()\n",
    "\n",
    "# get the time series for each sample\n",
    "# NOTE: coeffs.shape[0] == 5, one band for each regression coeff\n",
    "for i in range(coeffs.shape[1]):\n",
    "    for j in range(coeffs.shape[2]):\n",
    "        ts = np.sum(coeffs[:, i, j].values * dm, axis=1)\n",
    "        # rotate 1/2 year for southern-hemisphere sites, if stipulated\n",
    "        if rotate_s_hemis and row['y']<0:\n",
    "            ts = np.array([*ts[183:]] + [*ts[:183]])\n",
    "        # normalize time series [0,1], if desired\n",
    "        # NOTE: if not, pretty certain that first EOF will largely capture\n",
    "        #       global (i.e., across full subsetted extent) variation\n",
    "        #       in fitted magnitude\n",
    "        if normalize_ts and not np.any(np.isnan(ts)):\n",
    "            ts = normalize([ts]).flatten()\n",
    "        assert ts.shape == (365,)\n",
    "        ts_arr[:, i, j] = ts\n",
    "\n",
    "# once complete, save this to a simple numpy array file\n",
    "# (for now, anyhow; might be worth saving as a big geospatial file\n",
    "#  eventually?)\n",
    "if save_res:\n",
    "    np.savetxt(os.path.join(data_dir, 'fitted_ts_array.txt'),\n",
    "            ts_arr.reshape(ts_arr.shape[0], -1))\n",
    "\n",
    "    # load saved data and reshape it from 2d to 3d\n",
    "    ts_arr_2d = np.loadtxt(os.path.join(data_dir, 'fitted_ts_array.txt'))\n",
    "    ts_arr = ts_arr_2d.reshape(ts_arr_2d.shape[0],\n",
    "                               ts_arr_2d.shape[1] // coeffs.shape[2],\n",
    "                               coeffs.shape[2])\n",
    "\n",
    "# get coords arrays\n",
    "X, Y = np.meshgrid(coeffs.x, coeffs.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a39f0a9-4972-454a-ac61-09e0538426e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# RUN EOF\n",
    "#########\n",
    "if run_eof:\n",
    "\n",
    "    # calculate weights array requested\n",
    "    if lat_weights == 'cos':\n",
    "        weights = np.cos(np.deg2rad(Y))\n",
    "        weights /= weights.mean()\n",
    "    elif lat_weights == 'sqrt_cos':\n",
    "        weights = np.sqrt(np.cos(np.deg2rad(Y)))\n",
    "        weights /= weights.mean()\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "\n",
    "    # coerce ts array to rio xarray obj\n",
    "    ts_da = xr.DataArray([coeffs[0,:,:]*np.nan]*365) \n",
    "    ts_da.attrs = coeffs.attrs\n",
    "    ts_da.attrs['long_name'] = ['d%i' for i in range(1, 366)]\n",
    "    ts_da = ts_da.rename({'dim_0': 'time',\n",
    "                          'dim_1': 'y',\n",
    "                          'dim_2': 'x',\n",
    "                          })\n",
    "    ts_da = ts_da.assign_coords({'time': range(1, 366),\n",
    "                                 'y': coeffs.y.values,\n",
    "                                 'x': coeffs.x.values,\n",
    "                                 })\n",
    "    ts_da = ts_da.rio.write_crs(4326)\n",
    "    ts_da.rio.set_crs(4326)\n",
    "    ts_da.loc[:,:,:] = ts_arr\n",
    "\n",
    "    # use empirical orthogonal functions to collapse global ts into\n",
    "    # main modes of variation\n",
    "    solver = Eof(ts_da, weights=weights)\n",
    "\n",
    "    # grab the first n EOFs\n",
    "    # (and swap axes so that 3rd axis is of length neofs, to facilitate image\n",
    "    # plotting)\n",
    "    eofs = solver.eofsAsCorrelation(neofs=neofs)\n",
    "\n",
    "    # grab the PCs\n",
    "    pcs = solver.pcs(npcs=neofs, pcscaling=1)\n",
    "\n",
    "    # grab pct variances of EOFs\n",
    "    var_pcts = solver.varianceFraction(neofs)\n",
    "\n",
    "    # reconstruct the field using just the selected top EOFs\n",
    "    ts_recon = solver.reconstructedField(neofs)\n",
    "\n",
    "    # write eofs to file, if requested\n",
    "    if save_res:\n",
    "        fig_filename = '%s_%i_EOFs_%s%s%s.tif' % (region_name, neofs,\n",
    "                                                lat_weights + 'wts',\n",
    "                                                '_shemrot' * rotate_s_hemis,\n",
    "                                                '_normts' * normalize_ts,)\n",
    "        eof_res_for_file = eofs.to_dataset('mode')\n",
    "        eof_res_for_file = eof_res_for_file.rename_vars(\n",
    "                                        {i: 'eof%i' % i for i in range(neofs)})\n",
    "        eof_res_for_file.rio.to_raster(os.path.join(data_dir, fig_filename),\n",
    "                           dtype=np.float32,\n",
    "                           tags={'eof%i_pctvar' % i:\n",
    "                                 str(var_pcts.values[i]) for i in range(neofs)},\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4f4ae7-8d85-43ef-96b8-c98f10b27814",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_eof:\n",
    "    #########################################################################\n",
    "    # MAP AND PLOT CHARACTERISTIC SEASONAL PATTERNS AT ENDS OF EACH EOF RANGE\n",
    "    #########################################################################\n",
    "\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    gs = fig.add_gridspec(nrows=neofs, ncols=5, width_ratios=[1,0.3,1,0.3,1])\n",
    "    for neof in range(neofs):\n",
    "        ax_map = fig.add_subplot(gs[neof, 0])\n",
    "        eofs.sel(mode=neof).plot(ax=ax_map)\n",
    "        ax_map.set_aspect('equal')\n",
    "        ax_map.set_xticks(())\n",
    "        ax_map.set_yticks(())\n",
    "        ax_map.set_xticklabels(())\n",
    "        ax_map.set_yticklabels(())\n",
    "        ax_map.set_ylabel('mode %i' % neof, fontdict={'fontsize': 20})\n",
    "        ax_map.set_title('%0.1f%% of variation' % (var_pcts[neof]*100))\n",
    "        ax_pc_plot = fig.add_subplot(gs[neof,2])\n",
    "        ax_pc_plot.set_xlabel('time of year')\n",
    "        ax_pc_plot.set_xticks(np.linspace(0, 365, 5), ['Jan', 'Apr', 'Jul',\n",
    "                                                       'Oct', 'Jan'])\n",
    "        pcs.sel(mode=neof).plot(ax=ax_pc_plot)\n",
    "        ax_pc_plot.set_title('annual variation')\n",
    "        ax_pc_plot.set_ylabel('scaled PC value')\n",
    "        ax_examp_ts = fig.add_subplot(gs[neof,4])\n",
    "        for ts in ts_recon.values[:,\n",
    "            eofs.sel(mode=neof)>=np.nanpercentile(eofs.sel(mode=neof), 95)].T:\n",
    "            ax_examp_ts.plot(range(365), ts, alpha=0.1, color='#850c10')\n",
    "        for ts in ts_recon.values[:,\n",
    "            eofs.sel(mode=neof)<=np.nanpercentile(eofs.sel(mode=neof), 5)].T:\n",
    "            ax_examp_ts.plot(range(365), ts, alpha=0.1, color='#0b489e')\n",
    "        ax_examp_ts.set_xlabel('time of year')\n",
    "        ax_examp_ts.set_ylabel('scaled magnitude')\n",
    "        ax_examp_ts.set_title(('seasonality at 95th pctile (red)\\n'\n",
    "                            'and 5th pctile (blue) of mode %i pixels') % neof)\n",
    "        ax_examp_ts.set_xticks(np.linspace(0, 365, 5), ['Jan', 'Apr', 'Jul',\n",
    "                                                        'Oct', 'Jan'])\n",
    "    fig.subplots_adjust(left=subplots_adj_left,\n",
    "                         bottom=subplots_adj_bottom,\n",
    "                         right=subplots_adj_right,\n",
    "                         top=subplots_adj_top,\n",
    "                         wspace=subplots_adj_wspace,\n",
    "                         hspace=subplots_adj_hspace)\n",
    "    fig.show()\n",
    "    if save_res:\n",
    "        fig_filename = '%s_EOF_results_scat_%s%s%s.png' % (region_name,\n",
    "                                                lat_weights + 'wts',\n",
    "                                                '_shemrot' * rotate_s_hemis,\n",
    "                                                '_normts' * normalize_ts,)\n",
    "        fig.savefig(os.path.join(data_dir, fig_filename), dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179899e7-7f70-41cf-abda-9f3c0d6d1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_eof:\n",
    "    ##################################### \n",
    "    # USE HVPLOT FOR INTERACTIVE PLOTTING\n",
    "    ##################################### \n",
    "\n",
    "    eofs3 = solver.eofsAsCorrelation(neofs=3)\n",
    "    if interactive:\n",
    "\n",
    "        # plot top 3 EOFs as RGB image\n",
    "        rgb_plot = eofs3.hvplot.rgb(x='x', y='y', bands='mode',\n",
    "                                   geo=True,\n",
    "                                   #coastlines=True,\n",
    "                                   alpha=0.4,\n",
    "                                   #responsive=True,\n",
    "                                   width=800,\n",
    "                                   height=600,\n",
    "                                   title='top 3 EOFs in R, G, B channels',\n",
    "                                   tiles='EsriReference',\n",
    "                                   data_aspect=1)\n",
    "        pn.serve(rgb_plot)\n",
    "    else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917b63c4-9acb-4210-b7a6-40be591ecd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# EMBED IN 3D USING MDS\n",
    "#######################\n",
    "if run_mds:\n",
    "\n",
    "    # take subsample of full grid\n",
    "\n",
    "    # use metric multidimensional scaling to embed sample points' 365-length\n",
    "    # time series in 3-dimensional space (which I'll then map to RGB for mapping),\n",
    "    # using pairwise Euclidean distance between the 365-d points as dissim metric\n",
    "    mds_ts_arr = ts_arr.reshape(ts_arr.shape[0],-1).T\n",
    "    mds_ts_arr = mds_ts_arr[~np.isnan(mds_ts_arr).any(axis=1)]\n",
    "    mds = MDS(n_components=3, metric=True)\n",
    "    mds_axes = mds.fit_transform(mds_ts_arr)\n",
    "    # normalize the mds_axes columns, to then map onto RGB colors\n",
    "    mds_axes_norm = ((mds_axes - np.min(mds_axes, axis=0)) /\n",
    "                   (np.max(mds_axes, axis=0) - np.min(mds_axes, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e74bb3-0301-43f7-82fc-02099800c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_mds:\n",
    "    #####################################################\n",
    "    # PLOT IN 3D, AND MAP, AND PLOT CHARACTERISTIC CURVES\n",
    "    #####################################################\n",
    "\n",
    "    #grid MDS values\n",
    "    mds_res = coeffs[:3,:,:]*np.nan\n",
    "    mds_val_ct = 0\n",
    "    for x, y in zip(X.flatten(), Y.flatten()):\n",
    "        if not np.isnan(coeffs[0,:,:].sel(x=x, y=y)):\n",
    "            mds_res.loc[{'x':x, 'y':y}] = mds_axes_norm[mds_val_ct,:]\n",
    "            mds_val_ct += 1\n",
    "\n",
    "    # write gridded results to raster\n",
    "    try:\n",
    "        scale_factor = mds_res.attrs['scale_factor']\n",
    "    except Exception:\n",
    "        scale_factor = 1.\n",
    "    try:\n",
    "        add_offset = mds_res.attrs['add_offset']\n",
    "    except Exception:\n",
    "        add_offset = 0.\n",
    "    try:\n",
    "        _FillValue = mds_res.attrs['_FillValue']\n",
    "    except Exception:\n",
    "        _FillValue = -9999\n",
    "    mds_res.attrs.clear()\n",
    "    mds_res.attrs['scale_factor'] = scale_factor\n",
    "    mds_res.attrs['add_offset'] = add_offset\n",
    "    mds_res.attrs['_FillValue'] = _FillValue\n",
    "    mds_res.attrs['long_name'] = ['R', 'G', 'B']\n",
    "\n",
    "    outfilename = os.path.join(data_dir,  '%s_MDS_res.tif' % region_name)\n",
    "    mds_res.rio.to_raster(outfilename)\n",
    "\n",
    "\n",
    "    # map results\n",
    "    fig4 = plt.figure(figsize=(16,12))\n",
    "    gs = fig4.add_gridspec(nrows=6, ncols=4,\n",
    "                           width_ratios=[1,1,0.5,0.5])\n",
    "    ax_scat = fig4.add_subplot(gs[:3, 2:4], projection='3d')\n",
    "    ax_scat.scatter(mds_axes[:,0], mds_axes[:,1], mds_axes[:,2],\n",
    "                    c=mds_axes_norm, alpha=0.05)\n",
    "    ax_scat.set_xlabel('MDS AX 1')\n",
    "    ax_scat.xaxis.label.set_color('red')\n",
    "    ax_scat.set_ylabel('MDS AX 2')\n",
    "    ax_scat.yaxis.label.set_color('green')\n",
    "    ax_scat.set_zlabel('MDS AX 3')\n",
    "    ax_scat.zaxis.label.set_color('blue')\n",
    "    ax_scat.set_xticks(())\n",
    "    ax_scat.set_xticklabels(())\n",
    "    ax_scat.set_yticks(())\n",
    "    ax_scat.set_yticklabels(())\n",
    "    ax_scat.set_zticks(())\n",
    "    ax_scat.set_zticklabels(())\n",
    "\n",
    "    ax_map = fig4.add_subplot(gs[:,0:2])\n",
    "    countries = gpd.read_file(os.path.join(data_dir, 'NewWorldFile_2020.shp'))\n",
    "    countries = countries.to_crs(4326)\n",
    "    countries.plot(facecolor='none',\n",
    "                   edgecolor='black',\n",
    "                   linewidth=0.5,\n",
    "                   ax=ax_map)\n",
    "    mds_res.plot.imshow(ax=ax_map)\n",
    "    ax_map.set_xlim((np.min(coeffs.x), np.max(coeffs.x)))\n",
    "    ax_map.set_ylim((np.min(coeffs.y), np.max(coeffs.y)))\n",
    "    ax_map.set_xlabel('')\n",
    "    ax_map.set_ylabel('')\n",
    "    ax_map.set_xticks(())\n",
    "    ax_map.set_xticklabels(())\n",
    "    ax_map.set_yticks(())\n",
    "    ax_map.set_yticklabels(())\n",
    "    ax_map.set_title('')\n",
    "    ax_ax1_lo = fig4.add_subplot(gs[3,2])\n",
    "    ax_ax1_hi = fig4.add_subplot(gs[3,3])\n",
    "    ax_ax2_lo = fig4.add_subplot(gs[4,2])\n",
    "    ax_ax2_hi = fig4.add_subplot(gs[4,3])\n",
    "    ax_ax3_lo = fig4.add_subplot(gs[5,2])\n",
    "    ax_ax3_hi = fig4.add_subplot(gs[5,3])\n",
    "    for i in zip(*np.where(mds_axes[:,0]<=np.percentile(mds_axes[:,0], 5))):\n",
    "        ax_ax1_lo.plot(range(365), mds_ts_arr[i], alpha=0.1, color=mds_axes_norm[i])\n",
    "    for i in zip(*np.where(mds_axes[:,0]>=np.percentile(mds_axes[:,0], 95))):\n",
    "        ax_ax1_hi.plot(range(365), mds_ts_arr[i], alpha=0.1, color=mds_axes_norm[i])\n",
    "    for i in zip(*np.where(mds_axes[:,1]<=np.percentile(mds_axes[:,1], 5))):\n",
    "        ax_ax2_lo.plot(range(365), mds_ts_arr[i], alpha=0.1, color=mds_axes_norm[i])\n",
    "    for i in zip(*np.where(mds_axes[:,1]>=np.percentile(mds_axes[:,1], 95))):\n",
    "        ax_ax2_hi.plot(range(365), mds_ts_arr[i], alpha=0.1, color=mds_axes_norm[i])\n",
    "    for i in zip(*np.where(mds_axes[:,2]<=np.percentile(mds_axes[:,2], 5))):\n",
    "        ax_ax3_lo.plot(range(365), mds_ts_arr[i], alpha=0.1, color=mds_axes_norm[i])\n",
    "    for i in zip(*np.where(mds_axes[:,2]>=np.percentile(mds_axes[:,2], 95))):\n",
    "        ax_ax3_hi.plot(range(365), mds_ts_arr[i], alpha=0.1, color=mds_axes_norm[i])\n",
    "    ax_ax1_lo.set_ylabel('MDS AX1')\n",
    "    ax_ax1_lo.yaxis.label.set_color('red')\n",
    "    ax_ax2_lo.set_ylabel('MDS AX2')\n",
    "    ax_ax2_lo.yaxis.label.set_color('green')\n",
    "    ax_ax3_lo.set_ylabel('MDS AX3')\n",
    "    ax_ax3_lo.yaxis.label.set_color('blue')\n",
    "    ax_ax3_lo.set_xlabel('time of year')\n",
    "    ax_ax3_hi.set_xlabel('time of year')\n",
    "    ax_ax3_lo.set_xticks(np.linspace(0, 365, 5), ['Jan', 'Apr', 'Jul', 'Oct', 'Jan'])\n",
    "    ax_ax3_hi.set_xticks(np.linspace(0, 365, 5), ['Jan', 'Apr', 'Jul', 'Oct', 'Jan'])\n",
    "    for ax in [ax_ax1_lo, ax_ax1_hi, ax_ax2_lo, ax_ax2_hi, ax_ax3_lo, ax_ax3_hi]:\n",
    "        ax.set_yticks(())\n",
    "        ax.set_yticklabels(())\n",
    "    for ax in [ax_ax1_lo, ax_ax1_hi, ax_ax2_lo, ax_ax2_hi]:\n",
    "        ax.set_xticks(())\n",
    "        ax.set_xticklabels(())\n",
    "    fig4.subplots_adjust(left=subplots_adj_left,\n",
    "                         bottom=subplots_adj_bottom,\n",
    "                         right=subplots_adj_right,\n",
    "                         top=subplots_adj_top,\n",
    "                         wspace=subplots_adj_wspace,\n",
    "                         hspace=subplots_adj_hspace)\n",
    "    if save_res:\n",
    "        fig4_filename = '%s_MDS_results_scat.png' % region_name\n",
    "        fig4.savefig(os.path.join(data_dir, fig4_filename), dpi=100)\n",
    "    fig4.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
